import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from sentence_transformers import SentenceTransformer
from Tools.State_dict import StateDict
import pandas as pd
def agent_embedding(state: StateDict) -> StateDict:
    # SprawdÅº, czy model zostaÅ‚ juÅ¼ zaÅ‚adowany/wytrenowany w tej sesji LUB zaÅ‚adowany z dysku na poczÄ…tku
    if state.get("model") is not None:
        print("â„¹ï¸ [FineTuneEmbed] Model juÅ¼ istnieje w stanie (zaÅ‚adowany lub wczeÅ›niej dostrojony). Pomijanie ponownego dostrajania.")
        # Upewnijmy siÄ™, Å¼e globalne zmienne sÄ… zsynchronizowane ze stanem
        global embed_model, embed_fn
        if embed_model is not state["model"]: # JeÅ›li stan ma inny model niÅ¼ globalny
            print("ğŸ”„ Aktualizowanie globalnego modelu i funkcji embeddingÃ³w zgodnie ze stanem.")
            embed_model = state["model"]
            embed_fn = EmbeddingFunction(embed_model)
            if collection:
                collection.embedding_function = embed_fn # Zaktualizuj teÅ¼ w kolekcji ChromaDB
        return state

    # SprawdÅº, czy istnieje zapisany model na dysku (z poprzedniego uruchomienia),
    # jeÅ›li nie zostaÅ‚ zaÅ‚adowany na poczÄ…tku lub w stanie.
    # Ten kod jest trochÄ™ redundantny z komÃ³rkÄ… 2, ale zapewnia spÃ³jnoÅ›Ä‡.
    if os.path.isdir(MODEL_DIR) and os.listdir(MODEL_DIR):
          print(f"â„¹ï¸ [FineTuneEmbed] Znaleziono istniejÄ…cy model w {MODEL_DIR}. Åadowanie...")
          try:
              loaded_model = SentenceTransformer(MODEL_DIR)
              state["model"] = loaded_model # Zapisz zaÅ‚adowany model w stanie
              # Zaktualizuj globalne zmienne
              embed_model = loaded_model
              embed_fn = EmbeddingFunction(embed_model)
              if collection:
                  collection.embedding_function = embed_fn
              print("âœ… [FineTuneEmbed] PomyÅ›lnie zaÅ‚adowano istniejÄ…cy model. Pomijanie dostrajania.")
              return state
          except Exception as e:
               print(f"âš ï¸ Nie udaÅ‚o siÄ™ zaÅ‚adowaÄ‡ modelu z {MODEL_DIR}: {e}. PrÃ³ba dostrojenia od nowa.")
               # Nie ustawiaj state["model"], przejdÅº do dostrajania

    # --- Kontynuuj tylko, jeÅ›li nie zaÅ‚adowano modelu ---

    print("ğŸš€ [FineTuneEmbed] Rozpoczynanie procesu dostrajania modelu embeddingÃ³w.")
    if not state.get("pubmed_data") or not state.get("questions"):
        print("âš ï¸ [FineTuneEmbed] Brak danych PubMed lub pytaÅ„ w stanie. Nie moÅ¼na dostroiÄ‡ modelu.")
        state["model"] = embed_model # Ustaw model bazowy w stanie, jeÅ›li nic innego nie ma
        return state

    print("ğŸ“ [FineTuneEmbed] Przygotowywanie przykÅ‚adÃ³w treningowych (pozytywnych i negatywnych)...")
    examples: List[InputExample] = []
    all_ids_with_questions = list(state["questions"].keys()) # ID, dla ktÃ³rych mamy pytania

    positive_pairs = 0
    negative_pairs = 0

    # UÅ¼yj tylko danych, ktÃ³re majÄ… zarÃ³wno abstrakt, jak i pytania
    valid_data = [item for item in state["pubmed_data"] if item['id'] in state["questions"] and state["questions"][item['id']] and item.get("abstrakt")]

    if not valid_data:
         print("âš ï¸ [FineTuneEmbed] Brak danych z abstraktami i pytaniami do utworzenia przykÅ‚adÃ³w. Pomijanie dostrajania.")
         state["model"] = embed_model
         return state

    for rec in valid_data:
        rec_id = rec["id"]
        abstract = rec.get("abstrakt") # Wiemy, Å¼e istnieje i nie jest pusty z filtra powyÅ¼ej
        qs = state["questions"].get(rec_id, []) # Wiemy, Å¼e lista nie jest pusta

        # 1. PrzykÅ‚ady pozytywne: (pytanie z tego artykuÅ‚u, abstrakt tego artykuÅ‚u)
        for q in qs:
            if q and abstract: # Dodatkowe sprawdzenie poprawnoÅ›ci
                examples.append(InputExample(texts=[q, abstract], label=1.0))
                positive_pairs += 1

        # 2. PrzykÅ‚ady negatywne: (pytanie z INNEGO artykuÅ‚u, abstrakt TEGO artykuÅ‚u)
        # Wybierz kilka losowych ID innych niÅ¼ bieÅ¼Ä…cy, ktÃ³re majÄ… pytania
        possible_neg_ids = [pid for pid in all_ids_with_questions if pid != rec_id]
        num_neg_samples = min(len(possible_neg_ids), 3) # Ile negatywnych przykÅ‚adÃ³w na pozytywny

        if num_neg_samples > 0:
            neg_ids_sample = random.sample(possible_neg_ids, num_neg_samples)
            for neg_id in neg_ids_sample:
                neg_qs = state["questions"].get(neg_id, [])
                if neg_qs: # JeÅ›li dla negatywnego ID sÄ… pytania
                    # Wybierz losowe pytanie z negatywnego przykÅ‚adu
                    neg_q = random.choice(neg_qs)
                    if neg_q and abstract: # Upewnij siÄ™, Å¼e mamy oba teksty
                        examples.append(InputExample(texts=[neg_q, abstract], label=0.0))
                        negative_pairs += 1

    if not examples:
        print("âš ï¸ [FineTuneEmbed] Nie udaÅ‚o siÄ™ utworzyÄ‡ Å¼adnych przykÅ‚adÃ³w treningowych. Pomijanie dostrajania.")
        state["model"] = embed_model # Ustaw model bazowy
        return state

    print(f"ğŸ“Š Przygotowano {len(examples)} przykÅ‚adÃ³w treningowych ({positive_pairs} pozytywnych, {negative_pairs} negatywnych).")

    # --- Rozpocznij trening ---
    # UÅ¼yj bieÅ¼Ä…cego globalnego `embed_model` (moÅ¼e byÄ‡ bazowy lub zaÅ‚adowany z dysku)
    current_embed_model = embed_model
    print(f"ğŸ’ª Rozpoczynanie dostrajania modelu: {current_embed_model.__class__.__name__} (na bazie {MODEL_NAME} lub z {MODEL_DIR})")

    # Przygotuj DataLoader i funkcjÄ™ straty
    # ZwiÄ™ksz batch_size, jeÅ›li pamiÄ™Ä‡ GPU pozwala
    train_batch_size = 128
    loader = DataLoader(examples, shuffle=True, batch_size=train_batch_size)
    loss_fn = losses.CosineSimilarityLoss(model=current_embed_model)

    # Definicja callback'a (opcjonalnie, dla Å›ledzenia postÄ™pÃ³w)
    epochs_done = 0
    def simple_callback(score, epoch, steps):
        nonlocal epochs_done
        if epoch > epochs_done:
            print(f"Epoch {epoch+1} zakoÅ„czony. Åšrednia strata: {score:.4f}")
            epochs_done = epoch

    num_epochs = 1 # Trenuj przez jednÄ… epokÄ™ (moÅ¼na zwiÄ™kszyÄ‡ dla lepszych wynikÃ³w)
    warmup_steps = int(len(loader) * num_epochs * 0.1) # 10% krokÃ³w na rozgrzewkÄ™

    try:
        current_embed_model.fit(
            train_objectives=[(loader, loss_fn)],
            epochs=num_epochs,
            warmup_steps=warmup_steps,
            # callback=simple_callback, # WÅ‚Ä…cz, jeÅ›li chcesz widzieÄ‡ postÄ™p epok
            output_path=MODEL_DIR,      # Zapisuj model (checkpointy) tutaj
            show_progress_bar=True,     # PokaÅ¼ pasek postÄ™pu
            save_best_model=False       # Zapisz model po zakoÅ„czeniu ostatniej epoki
                                        # Ustaw True, jeÅ›li chcesz zapisywaÄ‡ najlepszy model na podstawie dev set (wymaga dev set)
        )
        print("âœ… [FineTuneEmbed] Dostrajanie zakoÅ„czone pomyÅ›lnie.")
        state["model"] = current_embed_model # Zapisz dostrojony model w stanie

        # Zaktualizuj globalny model i funkcjÄ™ embeddingÃ³w
        embed_model = current_embed_model
        embed_fn = EmbeddingFunction(embed_model)
        if collection:
            collection.embedding_function = embed_fn # Zaktualizuj funkcjÄ™ w ChromaDB
            print("âš™ï¸ Zaktualizowano funkcjÄ™ embeddingÃ³w w kolekcji ChromaDB.")

        # Zapisz finalny model (fit teÅ¼ zapisuje, ale dla pewnoÅ›ci)
        os.makedirs(MODEL_DIR, exist_ok=True)
        current_embed_model.save(MODEL_DIR)
        print(f"ğŸ’¾ Dostrojony model zapisany w {MODEL_DIR}")

    except Exception as e:
        print(f"âŒ BÅ‚Ä…d podczas procesu dostrajania modelu: {e}")
        # W razie bÅ‚Ä™du, zachowaj model sprzed prÃ³by dostrojenia w stanie
        # (zakÅ‚adamy, Å¼e `embed_model` nie zostaÅ‚ zmieniony przez nieudany `fit`)
        state["model"] = embed_model
        print("âš ï¸ UÅ¼ywany bÄ™dzie model sprzed nieudanej prÃ³by dostrojenia.")

    return state

print("Agent FineTuneEmbed zdefiniowany.")